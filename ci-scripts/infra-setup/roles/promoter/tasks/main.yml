# This role is meant to run in 3 different environments:
#  STANDALONE, ZUUL, and MOLECULE
#
# - STANDALONE (production promoter server in real host or vm)
#   should be run only after merging tested code, to actually provision the real server
#   with continuous deployment afterwards. RUNS THE ROLE AS ROOT
# - ZUUL ci job in staging promoter (nodepool node)
#   watch the test in your ci job
# - MOLECULE testing (local docker driver)
#   test and iterate over it before submitting changes
#   This environment should be taken into consideration, but major
#   task for it should be added in the molecule playbooks directly
#   and not here
#
#   ALL refers to all environments above


# This part of the role is continuously called by the production server
# as a mean for continuous delivery and code update in the server.
# The call in production is currently done by a root crontab installed a
# intance creation time by cloud-init.
# This can be changed in the future, but currently this role *MUST* be run
# as root especially in the tests, to mimic what's happening in production

- name: Check user id
  command: id -u
  register: user_id
  changed_when: false

- name: fail if this role is not run as root
  fail:
    msg: This role must be run as root.
  when: user_id.stdout != '0'

#
# Repos and packages
#

- name: Packages
  become: true
  block:
    - name: Configure docker-ce repo
      command: yum-config-manager --add-repo \
          https://download.docker.com/linux/centos/docker-ce.repo

    # Install EPEL so we can get ansible 2.8
    # Sometimes the epel.repo file is removed even if the package is installed.
    # So to get back the epel.repo file again we need to remove and install again.
    - name:  remove epel
      package:
        name: epel-release
        state: absent

    - name:  install epel
      package:
        name: epel-release
        state: present

    - name: Install influxdb repo to get telegraf
      yum_repository:
        name: influxdb
        description: InfluxDB Repository - RHEL \$releasever
        baseurl: https://repos.influxdata.com/rhel/\$releasever/\$basearch/stable
        enabled: yes
        gpgcheck: yes
        gpgkey: https://repos.influxdata.com/influxdb.key

    - name: Removed old/distro version of docker
      yum:
        name:
          - docker
          - docker-client
          - docker-client-latest
          - docker-common
          - docker-latest
          - docker-latest-logrotate
          - docker-logrotate
          - docker-engine
        state: absent

    - name: Install required packages
      yum:
        name:
          - logrotate
          - httpd
          - python-virtualenv
          - telegraf
          - yum-utils
          - device-mapper-persistent-data
          - lvm2
          - openssh
          - git
          - parted
          - docker-ce
          - docker-ce-cli
          - containerd.io
          - parted
          - xfsprogs
          - policycoreutils
          - setools-console
          - ansible
          - python-docker-py
        state: present

- name: Set up external partition
  become: true
  block:
    - name: Mount external volume - create a partition
      parted:
        device: "{{ docker_device }}"
        number: 1
        state: present

    - name: Be sure to reread partition table
      command: kpartx -a "{{ docker_device }}"
      when: setup_staging

    - name: Mount external volume - create a filesystem
      filesystem:
        fstype: xfs
        dev: "{{ docker_partition }}"

    - name: create a mount folder
      file:
        path: /var/lib/docker
        state: directory

    - name: Mount external volume - mount the partition
      mount:
        path: /var/lib/docker
        src: "{{ docker_partition }}"
        fstype: xfs
        state: mounted

#
# Docker configuration
#
- name: Configure Docker
  become: true
  block:
    - name: Ensure docker dir exists
      file:
        path: /etc/docker
        state: directory

    - name: Configure overlay2 for docker
      copy:
        content: |
          {
              "storage-driver": "overlay2",
              "storage-opts": [
                "overlay2.override_kernel_check=true"
              ]
          }
        dest: /etc/docker/daemon.json
      become: true
      register: docker_config

- name: Reload, enable and start docker
  when: not molecule_testing
  become: true
  block:
    - name: Reload docker if config was changed
      service:
        name: docker
        state: reloaded
      when: docker_config is changed

    - name: Start and enable Docker
      service:
        name: docker
        state: started
        enabled: yes

# Molecule docker driver it's the default and easiest provisioner to use
# unfortunately it has some limitations: you can't run docker daemon in it.
# so to test docker client actions we need to trick the client and the container itself.
# we are mounting the docker socket from the host to the container, but in a different
# location than default (it's a long story).
# So with the docker daemon mounted, the docker client can create containers in the host.
# Here we are getting the group from the socket file in the host, and adding the group to
# the user that is going to use the socket

- name: set default docker socket
  set_fact:
    docker_socket: /tmp/docker.sock

- name: Stat docker on docker socket
  stat:
    path: "{{ docker_socket }}"
  register: docker_socket_stat

- name: Adjust docker on docker setup
  when: not docker_socket_stat.stat.exists
  block:
    - name: set default docker socket
      set_fact:
        docker_socket: /var/run/docker.sock

- name: Stat docker socket again
  stat:
    path: "{{ docker_socket }}"
  register: docker_socket_stat

- name: Fail if no docker socket still
  when: not docker_socket_stat.stat.exists
  fail:
    msg: No docker socket

- name: Find out docker group name
  shell: |
    set -euo pipefail
    getent group {{ docker_socket_stat.stat.gid }} | cut -d":" -f1 | head -1
  register: docker_group
  changed_when: false
  failed_when: false

- when: not docker_group.stdout
  block:
    - name: Create docker group
      group:
        name: "docker_{{ docker_socket_stat.stat.gid }}"
        gid: "{{ docker_socket_stat.stat.gid }}"
        state: present

    - name: Storing new created docker group
      set_fact:
        docker_group:
          stdout: "docker_{{ docker_socket_stat.stat.gid }}"

- name: List groups for user
  command: "groups {{ promoter_user }}"
  register: user_groups
  changed_when: false

- name: Check if user is in docker group
  when: "docker_group.stdout not in user_groups.stdout"
  block:
    - name: Add user to docker group
      user:
        name: '{{ promoter_user }}'
        groups: '{{ docker_group.stdout }}'
        append: true
      register: groupadd

    - name: Reset connection for group add to take effect in the next tasks
      meta: reset_connection

- name: Create user config dir
  file:
    path: /home/{{ promoter_user }}/.docker/
    owner: "{{ promoter_user }}"
    state: directory

- name: Enable experimental commands in user config
  become: true
  become_user: "{{ promoter_user }}"
  copy:
    content: |
      {
          "experimental": "enabled"
      }
    dest: /home/{{ promoter_user }}/.docker/config.json


#
# Promoter logs and httpd service setup
#

- name: Fix home directory permissions
  file:
    path: "/home/{{ promoter_user }}"
    mode: 0755

- name: Create a directory for the promoter logs
  file:
    path: "/home/{{ promoter_user }}/promoter_logs"
    state: directory
    setype: httpd_sys_content_t
    owner: "{{ promoter_user }}"

- name: copy logrotate selinux policy
  copy:
    src: logrotate-promoter.te
    dest: /tmp/logrotate-promoter.te
  register: policy

- name: compile and permanently install policy
  shell: |
      checkmodule -M -m -o /tmp/logrotate-promoter.mod /tmp/logrotate-promoter.te
      semodule_package -m /tmp/logrotate-promoter.mod -o /tmp/logrotate-promoter.pp
      semodule -i /tmp/logrotate-promoter.pp
      rm -f /tmp/logrotate-promoter.pp /tmp/logrotate-promoter.mod
  when: policy is changed

- name: add configuration for the log rotation
  copy:
    content: |
        /home/{{ promoter_user }}/promoter_logs/*.log {
            daily
            missingok
            su {{ promoter_user }} {{ promoter_user }}
            dateext
            dateyesterday
            notifempty
            delaycompress
            rotate 60
        }
    dest: /etc/logrotate.d/promoter
    owner: root
    group: root
    mode: 0644
  become: true


#
# Apache setup (expose log)
#
- name: Disable the default welcome page
  copy:
    content: ''
    dest: '/etc/httpd/conf.d/welcome.conf'
    backup: yes
  become: true

- name: Add config file for Apache to expose the logs
  blockinfile:
    path: '/etc/httpd/conf.d/promoter_logs.conf'
    create: yes
    block: |
      <VirtualHost *:80>
          ServerAdmin rdo-ci-admins@redhat.com
          DocumentRoot /home/{{ promoter_user }}/promoter_logs

          <Directory /home/{{ promoter_user }}/promoter_logs>
              Options Indexes MultiViews
              AllowOverride None
              Require all granted
          </Directory>
      </VirtualHost>
  register: apache_config
  become: true

- name: Start and enable Apache
  service:
    name: httpd
    state: restarted
    enabled: yes
  become: true
  when: apache_config is changed

#
# Credential prepare
#
- name: Make sure .ssh dir exists
  file:
    path: "/home/{{ promoter_user }}/.ssh"
    state: directory
    mode: '0700'

#
# No credentials are handled in this part of the role
# Credentials are setup at instance creation time by cloud-init
# Continuous delivery doens't handle credentials at all, and credentials
# modification usually doesn't involve launching a whol provisioning role.
#

# in CD mode, this part of the role will at least keep these files
# restricted.

# If it's a deploy of the server to the cloud, need to copy secrets from /root


- name: Check if secrets are in root
  stat:
    path: "{{ item }}"
  loop:
    - "{{ provision_path_dlrnapi_secret_default }}"
    - "{{ provision_path_registry_secret_default }}"
    - "{{ provision_path_uploader_key_default }}"
  register: root_result

- name: Check if secrets are in user directory place
  stat:
    path: "{{ item }}"
  loop:
    - "{{ remote_path_dlrnapi_secret }}"
    - "{{ remote_path_registry_secret }}"
    - "{{ remote_path_uploader_key }}"
  register: user_result

- name: Print what will be copied and where
  debug: msg="Copying {{ item.0.item }} to {{ item.1.item }} "
  loop: "{{ root_result.results | zip(user_result.results) | list }}"
  when: item.0.stat.exists|bool and not item.1.stat.exists|bool

- name: Copy root credentials to user directory if need
  copy:
    src: "{{ item.0.item }}"
    dest: "{{ item.1.item }}"
    remote_src: true
  loop: "{{ root_result.results | zip(user_result.results) | list }}"
  when: item.0.stat.exists|bool and not item.1.stat.exists|bool

- block:
    - name: Fix owners of the files
      file:
        path: '{{ item }}'
        mode: '0600'
        owner: "{{ promoter_user }}"
      with_items:
          - "{{ remote_path_dlrnapi_secret  }}"
          - "{{ remote_path_registry_secret  }}"
          - "{{ remote_path_uploader_key  }}"
  rescue:
    - name: Possible Failure explanation
      debug:
        msg: Credentials ownership fix failed, probably a first run

#
# Ci-config repo handling
#
- name: Check for presence of repo on local machine
  become: false
  stat:
    path: "{{ ci_config_local_src_dir }}"
  register: ci_config_local_src_dir_stat
  delegate_to: localhost

- name: Check for presence of repo on server
  stat:
    path: "{{ ci_config_remote_src_dir }}"
  register: ci_config_remote_src_dir_stat

#
# Clone ci-config repo
#
- name: Understand from where to take the ci-config
  become: true
  become_user: "{{ promoter_user }}"
  block:

    - name: clone promoter dir from local dir if present
      synchronize:
        src: "{{ ci_config_local_src_dir }}/"
        dest: "{{ ci_config_remote_src_dir }}"
        rsync_opts:
            - "--no-motd"
            - "--exclude=.tox"
      when: ci_config_local_src_dir_stat.stat.exists

    - name: When dir is not present on the node, or locally, clone from git
      git:  # noqa 401
        repo: 'https://review.rdoproject.org/r/p/rdo-infra/ci-config.git'
        dest: "{{ ci_config_remote_src_dir }}"
      when:
        - not ci_config_local_src_dir_stat.stat.exists
        - not ci_config_remote_src_dir_stat.stat.exists

#
# Promoter preparation
#

- name: Create a virtualenv for the promoter script
  become: true
  become_user: "{{ promoter_user }}"
  pip:
    requirements: "{{ ci_config_remote_src_dir }}/ci-scripts/dlrnapi_promoter/requirements.txt"
    virtualenv: ~/promoter_venv

- name: Render promoter service script
  template:
    src: "dlrn-promoter-service.sh.j2"
    dest: "{{ ci_config_remote_src_dir }}/ci-scripts/dlrnapi_promoter/dlrn-promoter-service.sh"
    mode: '0755'
    owner: 'root'
    group: 'root'
  become: true

- name: Install promoter service
  copy:
    src: dlrn-promoter.service
    dest: /etc/systemd/system/
    mode: '0644'
    owner: 'root'
    group: 'root'
  become: true

# In staging setup the service file is a dumbed down version
# and we can start it to check that at least part of the syntax
# is ok
- name: Start and enable promoter
  systemd:
    name: dlrn-promoter
    state: started
    daemon_reload: yes
    enabled: yes
  become: true

#
# Monitoring setup
#
- block:
    - name: Configure telegraf to report to rrcockpit
      blockinfile:
        path: /etc/telegraf/telegraf.conf
        marker: "# -- {mark} ANSIBLE MANAGED BLOCK --"
        block: |
          [[outputs.influxdb]]
          urls = ['http://{{ rrcockpit_internal_network_ip }}:8086']
      become: true

    - name: Configure dlrn-promoter at telegraf
      copy:
        src: dlrn-promoter.telegraf.conf
        dest: /etc/telegraf/telegraf.d/dlrn-promoter.conf
        mode: '0644'
        owner: 'root'
        group: 'root'
      register: dlrn_promoter_telegram

    - name: Configure disk at telegraf
      copy:
        src: disk.telegraf.conf
        dest: /etc/telegraf/telegraf.d/disk.conf
        mode: '0644'
        owner: 'root'
        group: 'root'
      register: disk_telegram

    - name: Start and enable telegraf
      service:
        name: telegraf
        state: restarted
        enabled: yes
      when:
        - not setup_staging
        - dlrn_promoter_telegram.changed or disk_telegram.changed
  become: true
